\documentclass{article}

\usepackage[backend=biber]{biblatex}

% -- Title stuff --
\title{Concept Suggestor}
\date{17th of May, 2017}
\author{Rapha\"el Claasen}

% -- Bibliography --
\addbibresource{bibliography.bib}

% -- Actual Document --
\begin{document}

\maketitle

\begin{abstract}
This is the abstract.
\end{abstract}

{\bf Keywords:} NLP, semantic relatedness, semantic similarity

\section{Introduction}

ATM is a cross-disciplinary field that requires analysts from multiple domains such as security, safety, and business. When discussing problems about the ATM field, analysts often create domain-specific models that employ both shared and domain-specific concepts. To facilitate these discussions it is important that domain-specific models from one domain can be used in communication with other domains. This can be done by ensuring that domains use similar concepts in their models where possible.

It is difficult for analysts from different domains to communicate about their proposed solutions to a given ATM problem. This difficulty is partially caused by a difference in concepts used in their modeling which reduces the usefulness of these models in communication with other domains.

\section{Related Work}

Recommender systems are software tools and techniques providing suggestions for items to be of use to a user.\cite{ricci2011introduction}

WordNet is an electronic lexical database.\cite{kilgarriff2000wordnet}
SpaCy is one of the fastest and most accurate publicly available Natural Language Processing (NLP) toolkits available.\cite{choi2015depends}
SpaCy uses GloVe to create word vectors. GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus.\cite{pennington2014glove} Although GloVe measures co-occurrence and not semantic similarity or relatedness, its results can be used as a rough estimate of semantic similarity or relatedness.\cite{levy2015improving} SpaCy's default word vector library is trained on Wikipedia. Wikipedia has proven to be a valuable source for computing semantic relatedness measures.\cite{strube2006wikirelate}

Most methods of computing semantic relatedness measures such as word vectors rely on training an algorithm on a dataset. Public datasets, such as Google, Wikipedia, or WordNet are often used, although private datasets can also be used to improve context-sensitivity. Wikipedia and WordNet have proven to perform well in a variety of situations.\cite{strube2006wikirelate}

\section{Algorithms}

The Concept Suggestor uses several steps to decide which concepts get suggested to the user.

The first step is eliminating synonyms. A possible method of eliminating synonyms is comparing the similarity of words. The Concept Suggestor combines two algorithms for this: SpaCy's similarity function and WordNet's similarity function. The mean of these two algorithms is computed to determine overall word similarity.

\subsection{SpaCy}
SpaCy's word vectors are calculated by using the GloVe algorithm on Wikipedia. The similarity function of SpaCy computes the cosine of two word vectors. This results in a number between zero and one, where a value of zero indicates that two words are dissimilar, and a value of one indicates that two words are similar to each other.

\subsection{PyDictionary}
PyDictionary requests synonyms from the thesaurus.com website. The method looks whether two words can be found in each other's list of synonyms and returns a value of one if they can, and a value of zero if they can't. Some combinations of words, such as "airplane" and "aeroplane" are not found in each other's list of synonyms, but have identical lists of synonyms. Because of this, our method has been adapted to also look whether two words have identical lists of synonyms. If this is the case, the method also returns a value of one.

\subsection{WordNet}
WordNet is a public electronic lexical database that began in the mid-1980s in the Princeton University Department of Psychology and has been regularly updated and improved since then. The similarity function of WordNet returns a score between zero and one denoting how similar two words are, based on the shortest path that connects the senses in the is-a (hypernym/hyponym) taxonomy. % TODO: make the last sentence not plagiarism. Source: http://www.nltk.org/howto/wordnet.html 

WordNet offers several methods to measure similarity.
\begin{itemize}
	\item path\_similarity
	\item lch\_similarity
	\item wup\_similarity
	\item res\_similarity
	\item jcn\_similarity
	\item lin\_similarity
\end{itemize}

From these methods, the Wu-Palmer method is a good balance between performance and accuracy.\cite{budanitsky2006evaluating,seco2004intrinsic,mihalcea2006corpus}

\section{Evaluation Methodology}

% Just semantic similarity
Although there is no standard for computational evaluation of semantic similarity, there are generally three accepted methods.\cite{meng2013review}

Firstly, a theoretical examination of a computational measure can be made for those mathematical properties thought desirable, such as whether it is a metric, whether its parameter-projections are smooth functions, and so on. % TODO: Find out exactly what this means & rephrase it so I understand. It's quite complex language. Taken from meng2013review

Secondly, the coefficients of correlation with human judgement can be calculated, measured, and compared.\cite{zhou2008new,seco2004intrinsic}

Thirdly, if an application requires a measure of semantic similarity, we can compare the performance of different measures, while all other aspects of the application remain constant, to find the most effective measure.\cite{blanchard2006tree,budanitsky2006evaluating}

% Semantic similarity and relatedness
The techniques for measuring semantic similarity and relatedness can be roughly categorized into two main categories:\cite{agirre2009study} Those that rely on pre-existing knowledge, such as thesauri, encyclopedias, and semantic networks,\cite{alvarez2007graph,yang2005measuring,hughes2007lexical} and those inducing distributional properties of words from corpora.\cite{sahami2006web,chen2006novel,bollegala2007measuring}


% Below is subject matter that I want to have handled in this section.
\begin{itemize}
	\item How to measure similarity in concepts used in the various domain-specific models?
	\item How to determine which are relevant concepts from other models that should be suggested to a modeler in order to improve the alignment between the models?
	\item How to determine which are relevant concepts from elsewhere that might improve alignment between the models?
\end{itemize}

\section{Experiments}

These are the experiments.

\section{Conclusions}

These are the conclusions.

\section{Acknowledgements}

I would like to thank Fabiano Dalpiaz and Ba\c sak Aydemir for sharing expertise, valuable guidance, and encouragement with me.

\printbibliography

\end{document}